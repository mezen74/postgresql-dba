# Проектная работа
# Тема: Создание и тестирование высоконагруженного отказоустойчивого кластера PostgreSQL на базе Patroni

## Цели проекта

1. Развернуть на тестовом стенде отказоустойчивый кластер PostgreSQL на базе Patroni.
2. Разобраться с особенностями его настройки и эксплуатации.
3. Протестировать работу кластера в штатном режиме, а также при возникновении сбоев.
4. Рассмотреть возможность мониторинга работы кластера.
5. Оценить возможность использования Patroni для использования во внедрениях продуктов компании вместо Pacemaker.

## Используемые технологии

В проектной работе были использованы следующие продукты и технологии:

**Patroni** - это приложение для создания высокодоступных кластеров PostgreSQL на основе потоковой репликации. 
Меня в первую очередь привлекли в нём такие возможности:
- Поддержка автоматического контролируемого (switchover) и аварийного (failover) переключения;
- Легкое добавление новых реплик в существующий кластер; 
- Динамическое изменение конфигурации PostgreSQL одновременно на всех узлах кластера;
- Настраиваемые действия при переключении узлов;
- REST API.

**Etcd** - это отказоустойчивое распределенное хранилище типа ключ-значение. Такое хранилище необходимо Patroni для хранения состояния кластера PostgreSQL. Patroni может использовать и другие распределённые хранилища, такие как Consul, Zookeeper. Для установки на тестовом стенде мной был выбран etcd, так как у меня уже есть некоторый опыт его установки и эксплуатации. 

Отмечу, что на тестовом стенде у меня не развёрнут кластер etcd: используется только одна нода, запущенная на отдельном сервере. Это позволило мне сэкономить время на настройке etcd и больше внимания уделить изучению возможностей Patroni. Для рабочего окружения такой вариант не подходит: чтобы получить отказоустойчивое решение, необходимо несколько нод - не меньше трёх. И желательно, чтобы они были запущены не на тех же серверах, что и PostgreSQL.

**HAProxy** - серверное ПО для для обспечения высокой доступности и балансировки нагрузки. В проекте применяется для для того, чтобы перенаправлять клиентские соединения на мастер (для запросов на изменение) и на реплику (запросы на чтение)

**Confd** - это утилита для управления конфигурационными файлами. Она отслеживает изменения в хранилище, таком как etcd, consul, zookeeper, и на основании этих данных строит конфигурационные файлы по шаблону, после этого перезапускает сервис. В проекте используется для автоматического изменения конфигурационного файла HAProxy при изменении топологии кластера, например при добавлении новой реплики.

**Prometheus** - ПО для мониторинга, в проекте используется для сбора метрик от сервисов Patroni.

**Grafana** - платформа для визуализации данных, в проекте используется для отображения данных мониторинга кластера.

**Sysbench-tpcc** - набор скриптов для генерации нагрузки на базу данных, подобно тесту TPC-C.

## Конфигурация тестового стенда

Тестовый стенд развёрнут в Yandex Cloud.

Конфигурация виртуальных машин: 2 ядра, 4 Гб ОЗУ, SSD 20GB

Виртуальная сеть 192.168.2.0/24

Три виртуальных сервера:
- pg-proxy (192.168.2.10)
- pg-db1 (192.168.2.11)
- pg-db2 (192.168.2.12)

## Особенности настройки ПО
- Инструкции по установке и настройке ПО по [ссылке](https://github.com/mezen74/postgresql-dba/blob/main/patroni/doc/installation.md)
- Конфигурационные файлы по [сслыке](https://github.com/mezen74/postgresql-dba/tree/main/patroni/conf)

## Выполненные тесты

Подробные отчёты по тестам с указанием выполненных шагов, выводом команд, записями из логов по [ссылке](https://github.com/mezen74/postgresql-dba/blob/main/patroni/doc/tests.md).

### Штатные действия с кластером

#### Переключение мастера (switchover)

Выполнила переключение с помощью команды `patronictl switchower`. Было запрошено имя узла нового мастера и подтверждение. Каких-либо проблем в работе кластера не возникло.

#### Изменение динамической конфигурации Postgres средствами Patroni

Изменила конфигурацию с помощью команды `patronictl edit-config`.

Параметры, изменение которых не требует перезапуска PostgreSQL, были применены сразу на обоих серверах. Некоторые параметры требовали перезапуска. Patroni не выполнял перезапуск автоматически, это действие должен выполнить администратор. То, что требуется перезапуск PostgreSQL, было видно при просмотре состояния кластера, а также в логах были соответствующие записи.

Выполнила поочередно перезапуск PostgreSQL на обоих серверах командой `patronictl restart`. После перезапуска проверила: конфигурация была изменена на обоих серверах, новые параметры применены.

#### Штатная остановка сервиса Patroni через systemctl

Остановила Patroni с помощью команды `systemctl stop patroni`.

Штатная остановка Patroni не вызывает проблем в работе кластера. Прежде чем завершить работу, Patroni останавливает PostgreSQL

#### Завершение работы узла

Завершение работы узла (выключение виртуальной машины) не приводит к проблемам. Patroni штатно оставаливает PostgreSQL и завершает работу.

#### Добавление новой реплики в кластер

На новой ВМ установила Patroni и PostgreSQL, скопировала конфигурационный файл для Patroni, запустила Patroni.

Реплика была добавлена в кластер, на ней были применены параметры конфигурации PostgreSQL, общие для всего кластера.

В конфигурационном файле HAproxy демоном confd были добавлены записи для новой реплики.

### Тесты отказоустойчивости

#### Прерывание работы Postgres сигналом SIGKILL

Прервала работу PostgreSQL с помощью сигнала SIGKILL. Этот сигнал немедленно прекращает работу процесса, его невозможно игнорировать.

Patroni обнаружил что PostgreSQL не запущен и запустил его. Мастер не изменился. Отсюда вывод: Patroni отслеживает состояние PostgreSQL и в случае необходимости запускает его.

#### Приостановка/возобновление работы PostgreSQL сигналами SIGSTOP/SIGCONT 

Прервала работу PostgreSQL с помощью сигнала SIGSTOP. Этот сигнал немедленно приостанавливает выполнение процесса, при этом не завершая его. Этот сигнал также невозможно игнорировать.

В логах не появилось никаких записей. Выглядело это так, будто работу приостановил не только PostgreSQL, но и Patroni. На второй ноде Patroni обнаружил недоступность другого узла и поднял реплику до мастера.
HAProxy также обнаружил недоступность одной из нод и изменение мастера, и принудительно разорвал все соединения. Последующие соединения были направлены на новый мастер.

Возобновила работу PostgreSQL путём отправки ему сигнала SIGCONT. После возобновления работы PostgreSQL Patroni обнаружил что не может обновить блокировку в DCS и перевел PostgreSQL в режим реплики.

#### Прерывание работы Patroni сигналом SIGKILL

Отправила Patroni сигнал SIGKILL. Patroni прекратил работу, PostgreSQL продолжил работать.

На второй ноде Patroni обнаружил недоступность другого узла и поднял реплику до мастера.
HAProxy также обнаружил недоступность одной из нод и изменение мастера, и принудительно разорвал все соединения. Последующие соединения были направлены на новый мастер.

Patroni не был автоматически перезапущен. Автоматический перезапуск регулируется значением параметра в файле сервиса для systemd, по умолчанию systemd не пытается автоматически перезапустить Patroni. 

Запустила Patroni. После старта Patroni обнаружил, что не имеет блокировки и при этом является мастером, выполнил demotion и pg_rewind.

#### Приостановка/возобновление работы Patroni сигналами SIGSTOP/SIGCONT 

Прервала работу Patroni с помощью сигнала SIGSTOP.

На второй ноде Patroni обнаружил недоступность другого узла и поднял реплику до мастера.
HAProxy также обнаружил недоступность одной из нод и изменение мастера, и принудительно разорвал все соединения. Последующие соединения были направлены на новый мастер.

Возобновила работу Patroni путём отправки сигнала SIGCONT.  Patroni обнаружил, что не имеет блокировки и при этом является мастером, выполнил demotion.

#### Остановка etcd

Остановила etcd командой: `systemctl stop etcd`.

При недоступности etcd оба сервера перешли в режим реплики. После восстановления доступности etcd был выбран новый мастер и кластер продолжил работу в обычном режиме. Splitbrain-а и повреждения данных не произошло, работа кластера была восстановлена автоматически, перезапускать PostgreSQL и Patroni не потребовалось

### Тестирование работы кластера под нагрузкой

Выполнила тестирование кластера с помощью sysbench-tpcc.
Наблюдала при этом за отображением метрик в мониторинге.
Никаких проблем при тестировании кластера под нагрузкой не возникло.

## Настройка мониторинга

Patroni даёт доступ к метрикам через запросы RestAPI на адрес /metrics.
Метрики в формате Prometheus. 

В Prometheus добавила в конфигурационный файл адреса нод Patroni, в Grapana в качестве источника данных указала адрес prometheus

В Grafana импортировала dashboard id [18870](https://grafana.com/grafana/dashboards/18870-postgresql-patroni/).


## Выводы

По результатам проведенных тестов можно сделать вывод, что Patroni обеспечивает отказоустойчивость и высокую доступность кластера PostgreSQL: во время тестов ни разу не случился splitbrain, не было прерывания работы PostgreSQL, не случилось повреждения данных. В случае отказа сервисов кластер ведёт себя предсказуемо.

Основная точка отказа в кластере Patroni - это хранилище конфигурации. Когда оно недоступно, все сервера переходят в режим реплики. Поэтому нужно особое внимание уделить выбору и настройке хранилища конфигурации: обязательно развернуть кластер, с нечётным числом нод, желательно на отдельных серверах. Но следует отметить, что даже при недоступности хранилища конфигурации не происходит splitbrain, а после восстановления доступности хранилища кластер быстро восстанавливает работу.

Patroni предоставляет удобные средства управления кластером: есть утилита командной строки patronictl, есть возможность управлять кластером через запросы к REST Api. Также через REST Api можно получать данные для мониторинга кластера.

Легко выполнять обычные действия по управлению кластером, такие как переключение мастера, перезапуск PostgreSQL, добавление в кластер новой реплики.

Очень удобна возможность динамически менять конфигурацию PostgreSQL на всех узлах кластера одновременно. Это снижает затраты времени на переконфигурирование PostgreSQL и минимизирует количество ошибок. 

Если сравнивать Patroni и Pacemaker, то нужно учитывать, что это несколько разные классы ПО: Pacemaker позволяет управлять ресурсами различных типов, а Patroni прендназначен только для управления кластером PostgreSQL на основе потоковой репликации. Из этого следует, что Pacemaker более универсальное решение, которое можно использовать для большого класса задач. Но зато Patroni предоставляет больше возможностей по управлению кластером PostgreSQL.
